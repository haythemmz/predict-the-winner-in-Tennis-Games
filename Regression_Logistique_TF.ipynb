{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/helmi/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.42706626,  0.13985797,  0.27001278, ..., -3.30653266,\n",
       "        -0.39347982,  0.51542206],\n",
       "       [ 0.13941895, -0.52060659,  0.66711661, ..., -1.77889447,\n",
       "        -0.44500362,  0.93784994],\n",
       "       [ 0.12687574,  1.01325975,  0.15535855, ...,  1.10552764,\n",
       "        -0.2864642 , -0.19288726],\n",
       "       ...,\n",
       "       [-0.60769195,  0.59612979,  1.37291676, ..., -0.        ,\n",
       "        -0.63054687, -0.00784261],\n",
       "       [-0.10665123, -0.02384519,  1.22197312, ...,  0.2361809 ,\n",
       "        -0.56187814, -1.01922979],\n",
       "       [-0.00776943,  1.4644058 ,  2.23509447, ..., -0.        ,\n",
       "        -0.27282043, -0.09883803]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importation des bibliothèques nécessaires \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import time \n",
    "import tensorflow as tf \n",
    "from sklearn.preprocessing import robust_scale\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# lecteur des données pour l'entrainement du modèle \n",
    "df=pd.read_csv('donnee/data.csv',header=0,index_col=0)\n",
    "\n",
    "# céation de numpy array qui sera utilisé pour l'entrainement et le test du modèle \n",
    "X= df.iloc[:,4:-1]\n",
    "names = X.columns\n",
    "X=X.values\n",
    "# création des données pour les deux classes \n",
    "Y= np.random.choice(2, X.shape[0]).reshape(X.shape[0],1)\n",
    "for i in range(len(Y)):\n",
    "    if Y[i]==0:\n",
    "        X[i,:]=-X[i,:]\n",
    "# standardisation des données ( rosbust aux outliars)\n",
    "X=robust_scale(X)\n",
    "# division des données en entrainement et test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state=0,test_size=0.25)\n",
    "\n",
    "# nombres des variable et nombre des classe \n",
    "num_features = X_train.shape[1]\n",
    "num_classes =  Y_train.shape[1]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création des placeholders les trous qui seront remplis par les données d'entrainemet\n",
    "x = tf.placeholder( shape=[None, num_features] ,dtype=tf.float32 )\n",
    "y = tf.placeholder(shape=[None, num_classes] , dtype=tf.float32)\n",
    "\n",
    "#les paramétres du modèle \n",
    "W = tf.Variable(tf.zeros([num_features,num_classes]),dtype=tf.float32)\n",
    "B = tf.Variable(tf.zeros([num_classes]),dtype=tf.float32)\n",
    "\n",
    "# la fonction du regression lostique \n",
    "pY =tf.nn.sigmoid(tf.matmul(x, W) + B)\n",
    "# fonction cout à minimiser \n",
    "cost_fn= tf.reduce_mean(tf.reduce_sum((-y * tf.log(pY)) - ((1 - y) * tf.log(1 - pY)), reduction_indices=[1]))# You could also put it in a more explicit way\n",
    "\n",
    "# optimizer adam plus rapide que Gradient descent sa pas change selon la valeur de dérivé \n",
    "optimizer = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les hyper-paramètres \n",
    "learning_rate=0.01\n",
    "match_number=X.shape[0]\n",
    "features_number=X.shape[1]\n",
    "batch_size=100\n",
    "number_batchs=int(match_number/batch_size)\n",
    "n_epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choisir un batch de façon aléatoire pour l'entrainement du modèle en donnant la taille de batch \n",
    "def batch_choice(x,y, batch_size):\n",
    "    indexs=np.random.choice(a=x.shape[0],size=batch_size,replace=False)\n",
    "    x=x[indexs,:]\n",
    "    y=y[indexs,:]\n",
    "    return x.astype(float),y.astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction de prédection \n",
    "def pred(x):\n",
    "    l=[]\n",
    "    for i in list(x) :\n",
    "        if i > 0.5 :\n",
    "            l.append(1)\n",
    "        else:\n",
    "            l.append(0)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction score \n",
    "def score (x,y):\n",
    "    l=[]\n",
    "    for i,j in zip (x,y):\n",
    "        if i==j:\n",
    "            l.append(1)\n",
    "        else:\n",
    "            l.append(0)\n",
    "    return (np.mean(l))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# entrainement du modèle \n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "costs=[]\n",
    "scores=[]\n",
    "for i in range(n_epochs):\n",
    "    avg_cost = 0.\n",
    "        \n",
    "    for i in range(number_batchs):\n",
    "        x_train , y_train = batch_choice (X_train, Y_train , batch_size)\n",
    "        model = sess.run(optimizer, feed_dict={x:x_train,y:y_train})\n",
    "        c = sess.run(cost_fn, feed_dict={x:x_train,y:y_train})\n",
    "        avg_cost+=c/batch_size\n",
    "           \n",
    "    costs.append(avg_cost)\n",
    "    p=sess.run(pY , feed_dict={x:X_test})\n",
    "    prediction=pred(p)\n",
    "    scores.append(score(prediction,Y_test))\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=sess.run(pY , feed_dict={x:X_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
